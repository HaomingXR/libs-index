<h1 align="center"> Libraries Index </h1>
<p align="center">This repository provides information on how to obtain certain resources<br>

## TensorRT
- **GitHub:** https://github.com/NVIDIA/TensorRT

1. Download the `.zip` for your speicific platform from the following link *(an **NVIDIA Developer Account** is required)*
    - https://developer.nvidia.com/tensorrt-download
2. Inside the `python` folder, you should see the `.whl` files for installation
3. The `trtexec` executable is also included in the `bin` folder

## triton
- **GitHub:** https://github.com/openai/triton

> [!WARNING]
> - Triton officially does **not** support Windows
> - Though there are attmpts made to build a package for Windows
> - However, some claim to see no noticable improvements after installing the package
> - Additionally, as the package is built by a third-party, installation discretion is advised

<details>
<summary><b>Non-Official</b> Download Links</summary>

- https://github.com/openai/triton/pull/2738
- https://huggingface.co/r4ziel/xformers_pre_built/tree/main
</details>

## torch2trt
- **GitHub:** https://github.com/NVIDIA-AI-IOT/torch2trt

Simply clone the repo and follow the instructions to build

<p align="right"><sub><i>A pre-built is provided</i></sub></p>

## websocket-sharp
- **GitHub:** https://github.com/sta/websocket-sharp

Simply clone the repo and follow the instructions to build

<p align="right"><sub><i>A pre-built is provided</i></sub></p>

<hr>

<details>
<summary>My System Environment</summary>

- **OS:** Windows 11
- **Python:** 3.10.10
- **CUDA:** 11.8
- **cuDNN:** v8.5.0.96
- **Driver:** 546.01
</details>
